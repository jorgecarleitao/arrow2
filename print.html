<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>arrow2 documentation</title>
                <meta name="robots" content="noindex" />
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="index.html"><strong aria-hidden="true">1.</strong> Arrow2</a></li><li class="chapter-item expanded "><a href="arrow.html"><strong aria-hidden="true">2.</strong> The arrow format</a></li><li class="chapter-item expanded "><a href="low_level.html"><strong aria-hidden="true">3.</strong> Low-level API</a></li><li class="chapter-item expanded "><a href="high_level.html"><strong aria-hidden="true">4.</strong> High-level API</a></li><li class="chapter-item expanded "><a href="compute.html"><strong aria-hidden="true">5.</strong> Compute</a></li><li class="chapter-item expanded "><a href="metadata.html"><strong aria-hidden="true">6.</strong> Metadata</a></li><li class="chapter-item expanded "><a href="ffi.html"><strong aria-hidden="true">7.</strong> Foreign interfaces</a></li><li class="chapter-item expanded "><a href="io/index.html"><strong aria-hidden="true">8.</strong> IO</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="io/csv_reader.html"><strong aria-hidden="true">8.1.</strong> Read CSV</a></li><li class="chapter-item expanded "><a href="io/csv_write.html"><strong aria-hidden="true">8.2.</strong> Write CSV</a></li><li class="chapter-item expanded "><a href="io/parquet_read.html"><strong aria-hidden="true">8.3.</strong> Read Parquet</a></li><li class="chapter-item expanded "><a href="io/parquet_write.html"><strong aria-hidden="true">8.4.</strong> Write Parquet</a></li><li class="chapter-item expanded "><a href="io/ipc_read.html"><strong aria-hidden="true">8.5.</strong> Read Arrow</a></li><li class="chapter-item expanded "><a href="io/ipc_write.html"><strong aria-hidden="true">8.6.</strong> Write Arrow</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">arrow2 documentation</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="arrow2"><a class="header" href="#arrow2">Arrow2</a></h1>
<p>Arrow2 is a Rust library that implements data structures and functionality enabling
interoperability with the arrow format.</p>
<p>The typical use-case for this library is to perform CPU and memory-intensive analytics in a format that supports heterogeneous data structures, null values, and IPC and FFI interfaces across languages.</p>
<p>Arrow2 is divided into three main parts: </p>
<ul>
<li>a <a href="./low_level.html">low-level API</a> to efficiently operate with contiguous memory regions;</li>
<li>a <a href="./high_level.html">high-level API</a> to operate with arrow arrays;</li>
<li>a <a href="./metadata.html">metadata API</a> to declare and operate with logical types and metadata.</li>
</ul>
<h2 id="cargo-features"><a class="header" href="#cargo-features">Cargo features</a></h2>
<p>This crate has a significant number of cargo features to reduce compilation times and dependencies blowup.
There is also a feature <code>simd</code>, that requires the nightly channel, that produces more explicit SIMD instructions via <a href="https://github.com/rust-lang/packed_simd"><code>packed_simd</code></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>Welcome to the Arrow2 guide for the Rust programming language.  This guide was
created to help you become familiar with the Arrow2 crate and its
functionalities.</p>
<h2 id="what-is-apache-arrow"><a class="header" href="#what-is-apache-arrow">What is Apache Arrow?</a></h2>
<p>According to its <a href="https://arrow.apache.org">website</a> Apache Arrow is defined
as:</p>
<blockquote>
<p>A language-independent columnar memory format for flat and hierarchical data,
organized for efficient analytic operations on modern hardware like CPUs and
GPUs. The Arrow memory format also supports zero-copy reads for
lightning-fast data access without serialization overhead.</p>
</blockquote>
<p>After reading the description you have probably come to the conclusion that
Apache Arrow sounds great and that it will give anyone working with data enough
tools to improve a data processing workflow.  But that's the catch, on its own
Apache Arrow is not an application or library that can be installed and used.
The objective of Apache Arrow is to define a set of specifications that need to
be followed by an implementation in order to allow:</p>
<ol>
<li>fast in-memory data access</li>
<li>sharing and zero copy of data between processes</li>
</ol>
<h3 id="fast-in-memory-data-access"><a class="header" href="#fast-in-memory-data-access">Fast in-memory data access</a></h3>
<p>Apache Arrow allows fast memory access by defining its <a href="https://arrow.apache.org/overview/">in-memory columnar
format</a>. This columnar format defines a
standard and efficient in-memory representation of various datatypes, plain or
nested
(<a href="https://github.com/apache/arrow/blob/master/docs/source/format/Columnar.rst">reference</a>).</p>
<p>In other words, the Apache Arrow project has created a series of rules or
specifications to define how a datatype (int, float, string, list, etc.) is
stored in memory. Since the objective of the project is to store large amounts
of data in memory for further manipulation or querying, it uses a columnar data
definition. This means that when a dataset (data defined with several columns)
is stored in memory, it no longer maintains its rows representation but it is
changed to a columnar representation.</p>
<p>For example, lets say we have a dataset that is defined with three columns
named: <em>session_id</em>, <em>timestamp</em> and <em>source_id</em> (image below). Traditionally,
this file should be represented in memory maintaining its row representation
(image below, left). This means that the fields representing a row would be kept
next to each other. This makes memory management harder to achieve because there
are different datatypes next to each other; in this case a long, a date and a
string. Each of these datatypes will have different memory requirements (for
example, 8 bytes, 16 bytes or 32 bytes).</p>
<p align="center">
  <img src="images/simd.png">
</p>
<p>By changing the in memory representation of the file to a columnar form (image
above, right), the in-memory arrangement of the data becomes more efficient.
Similar datatypes are stored next to each other, making the access and columnar
querying faster to perform.</p>
<h3 id="sharing-data-between-processes"><a class="header" href="#sharing-data-between-processes">Sharing data between processes</a></h3>
<p>Imagine a typical workflow for a data engineer. There is a process that is
producing data that belongs to a service monitoring the performance of a sales
page.  This data has to be read, processed and stored. Probably the engineer
would first set a script that is reading the data and storing the result in a
CSV or Parquet file. Then the engineer would need to create a pipeline to read
the file and transfer the data to a database. Once the data is stored some
analysis is needed to be done on the data, maybe Pandas is used to read the data
and extract information. Or, perhaps Spark is used to create a pipeline that
reads the database in order to create a stream of data to feed a dashboard. The
copy and convert process may end up looking like this:</p>
<p align="center">
  <img src="images/copy.png">
</p>
<p>As it can be seen, the data is copied and converted several times. This happens
every time a process needs to query the data.</p>
<p>By using a standard that all languages and processes can understand, the data
doesn't need to be copied and converted. There can be a single in-memory data
representation that can be used to feed all the required processes. The data
sharing can be done regarding the language that is used.</p>
<p align="center">
  <img src="images/shared.png">
</p>
<p>And thanks to this standardization the data can also be shared with processes
that don't share the same memory. By creating a data server, packets of data
with known structure (RecordBatch) can be sent across computers (or pods) and
the receiving process doesn't need to spend time coding and decoding the data
to a known format. The data is ready to be used once its being received.</p>
<p align="center">
  <img src="images/recordbatch.png">
</p>
<h2 id="the-arrow2-crate"><a class="header" href="#the-arrow2-crate">The Arrow2 crate</a></h2>
<p>These and other collateral benefits can only be achieved thanks to the work done
by the people collaborating in the Apache Arrow project. By looking at the
project <a href="https://github.com/apache/arrow">github page</a>, there are libraries for
the most common languages used today, and that includes Rust.</p>
<p>The Rust Arrow2 crate is a collection of structs and implementations that define
all the elements required to create Arrow arrays that follow the Apache Arrow
specification. In the next sections the basic blocks for working with the
crate will be discussed, providing enough examples to give you familiarity
to construct, share and query Arrow arrays.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="low-level-api"><a class="header" href="#low-level-api">Low-level API</a></h1>
<p>The starting point of this crate is the idea that data must be stored in memory in a specific arrangement to be interoperable with Arrow's ecosystem. With this in mind, this crate does not use <code>Vec</code> but instead has its own containers to store data, including sharing and consuming it via FFI.</p>
<p>The most important design decision of this crate is that contiguous regions are shared via an <code>Arc</code>. In this context, the operation of slicing a memory region is <code>O(1)</code> because it corresponds to changing an offset and length. The tradeoff is that once under an <code>Arc</code>, memory regions are immutable.</p>
<p>The second important aspect is that Arrow has two main types of data buffers: bitmaps, whose offsets are measured in bits, and byte types (such as <code>i32</code>), whose offsets are measured in bytes. With this in mind, this crate has 2 main types of containers of contiguous memory regions:</p>
<ul>
<li><code>Buffer&lt;T&gt;</code>: handle contiguous memory regions of type T whose offsets are measured in items</li>
<li><code>Bitmap</code>: handle contiguous memory regions of bits whose offsets are measured in bits</li>
</ul>
<p>These hold <em>all</em> data-related memory in this crate.</p>
<p>Due to their intrinsic immutability, each container has a corresponding mutable (and non-shareable) variant:</p>
<ul>
<li><code>MutableBuffer&lt;T&gt;</code></li>
<li><code>MutableBitmap</code></li>
</ul>
<p>Let's see how these structures are used.</p>
<p>Create a new <code>Buffer&lt;u32&gt;</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use arrow2::buffer::Buffer;
</span><span class="boring">fn main() {
</span>let x = Buffer::from(&amp;[1u32, 2, 3]);
assert_eq!(x.as_slice(), &amp;[1u32, 2, 3]);

let x = x.slice(1, 2);
assert_eq!(x.as_slice(), &amp;[2, 3]);
<span class="boring">}
</span></code></pre></pre>
<p>Using a <code>MutableBuffer&lt;i64&gt;</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use arrow2::buffer::MutableBuffer;
</span><span class="boring">fn main() {
</span>let mut x: MutableBuffer&lt;i64&gt; = (0..3).collect();
x[1] = 5;
x.push(10);
assert_eq!(x.as_slice(), &amp;[0, 5, 2, 10])
<span class="boring">}
</span></code></pre></pre>
<p>The following demonstrates how to efficiently
perform an operation from an iterator of <a href="https://doc.rust-lang.org/std/iter/trait.TrustedLen.html">TrustedLen</a>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use arrow2::buffer::MutableBuffer;
</span><span class="boring">fn main() {
</span>let x = (0..1000).collect::&lt;Vec&lt;_&gt;&gt;();
let y = MutableBuffer::from_trusted_len_iter(x.iter().map(|x| x * 2));
assert_eq!(y[50], 100);
<span class="boring">}
</span></code></pre></pre>
<p>Using <code>from_trusted_len_iter</code> often causes the compiler to auto-vectorize.</p>
<p>In this context, <code>MutableBuffer</code> has an almost identical API to Rust's <code>Vec</code>.
However, contrarily to <code>Vec</code>, <code>Buffer</code> and <code>MutableBuffer</code> only supports
the following physical types:</p>
<ul>
<li><code>i8-i128</code></li>
<li><code>u8-u64</code></li>
<li><code>f32</code> and <code>f64</code></li>
<li><code>arrow2::types::days_ms</code></li>
</ul>
<p>This is because the arrow specification only supports the above Rust types; all other complex
types supported by arrow are built on top of these types, which enables Arrow to be a highly
interoperable in-memory format.</p>
<h2 id="bitmaps"><a class="header" href="#bitmaps">Bitmaps</a></h2>
<p>Arrow's in-memory arrangement of boolean values is different from <code>Vec&lt;bool&gt;</code>. Specifically,
arrow uses individual bits to represent a boolean, as opposed to the usual byte that <code>bool</code> holds.
Besides the 8x compression, this makes the validity particularly useful for 
<a href="https://en.wikipedia.org/wiki/AVX-512">AVX512</a> masks.
One tradeoff is that an arrows' bitmap is not represented as a Rust slice, as Rust slices use
pointer arithmetics, whose smallest unit is a byte.</p>
<p>Arrow2 has two containers for bitmaps: <code>Bitmap</code> (immutable and sharable)
and <code>MutableBitmap</code> (mutable):</p>
<pre><pre class="playground"><code class="language-rust">use arrow2::bitmap::Bitmap;
<span class="boring">fn main() {
</span>let x = Bitmap::from(&amp;[true, false]);
let iter = x.iter().map(|x| !x);
let y = Bitmap::from_trusted_len_iter(iter);
assert_eq!(y.get_bit(0), false);
assert_eq!(y.get_bit(1), true);
<span class="boring">}
</span></code></pre></pre>
<pre><pre class="playground"><code class="language-rust">use arrow2::bitmap::MutableBitmap;
<span class="boring">fn main() {
</span>let mut x = MutableBitmap::new();
x.push(true);
x.push(false);
assert_eq!(x.get(1), false);
x.set(1, true);
assert_eq!(x.get(1), true);
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="high-level-api"><a class="header" href="#high-level-api">High-level API</a></h1>
<p>The simplest way to think about an arrow <code>Array</code> is that it represents
<code>Vec&lt;Option&lt;T&gt;&gt;</code> and has a logical type (see <a href="../metadata.html">metadata</a>)) associated with it.</p>
<p>Probably the simplest array in this crate is <code>PrimitiveArray&lt;T&gt;</code>. It can be constructed
from an iterator as follows:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use arrow2::array::{Array, PrimitiveArray};
</span><span class="boring">use arrow2::datatypes::DataType;
</span><span class="boring">fn main() {
</span>let array = [Some(1), None, Some(123)]
    .iter()
    .collect::&lt;PrimitiveArray&lt;i32&gt;&gt;();
assert_eq!(array.len(), 3)
<span class="boring">}
</span></code></pre></pre>
<p>A <code>PrimitiveArray</code> has 3 components:</p>
<ol>
<li>A physical type (<code>i32</code>)</li>
<li>A logical type (e.g. <code>DataType::Int32</code>)</li>
<li>Data</li>
</ol>
<p>The main differences from a <code>Vec&lt;Option&lt;T&gt;&gt;</code> are:</p>
<ul>
<li>Its data is laid out in memory as a <code>Buffer&lt;T&gt;</code> and an <code>Option&lt;Bitmap&gt;</code>.</li>
<li>It has an associated logical datatype.</li>
</ul>
<p>The first difference allows interoperability with Arrow's ecosystem and efficient SIMD operations (we will re-visit this below); the second difference is that it gives semantic meaning to the array. In the example</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use arrow2::array::PrimitiveArray;
</span><span class="boring">use arrow2::datatypes::DataType;
</span><span class="boring">fn main() {
</span>let ints = PrimitiveArray::&lt;i32&gt;::from(&amp;[Some(1), None]).to(DataType::Int32);
let dates = PrimitiveArray::&lt;i32&gt;::from(&amp;[Some(1), None]).to(DataType::Date32);
<span class="boring">}
</span></code></pre></pre>
<p><code>ints</code> and <code>dates</code> have the same in-memory representation but different logic representations (e.g. dates are usually represented as a string).</p>
<p>Some physical types (e.g. <code>i32</code>) have a &quot;natural&quot; logical <code>DataType</code> (e.g. <code>DataType::Int32</code>).
These types support a more compact notation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use arrow2::array::{Array, Int32Array, PrimitiveArray};
</span><span class="boring">use arrow2::datatypes::DataType;
</span><span class="boring">fn main() {
</span>/// Int32Array = PrimitiveArray&lt;i32&gt;
let array = [Some(1), None, Some(123)].iter().collect::&lt;Int32Array&gt;();
assert_eq!(array.len(), 3);
let array = Int32Array::from(&amp;[Some(1), None, Some(123)]);
assert_eq!(array.len(), 3);
let array = Int32Array::from_slice(&amp;[1, 123]);
assert_eq!(array.len(), 2);
<span class="boring">}
</span></code></pre></pre>
<p>The following arrays are supported:</p>
<ul>
<li><code>NullArray</code> (just holds nulls)</li>
<li><code>BooleanArray</code> (booleans)</li>
<li><code>PrimitiveArray&lt;T&gt;</code> (for ints, floats)</li>
<li><code>Utf8Array&lt;i32&gt;</code> and <code>Utf8Array&lt;i64&gt;</code> (for strings)</li>
<li><code>BinaryArray&lt;i32&gt;</code> and <code>BinaryArray&lt;i64&gt;</code> (for opaque binaries)</li>
<li><code>FixedSizeBinaryArray</code> (like <code>BinaryArray</code>, but fixed size)</li>
<li><code>ListArray&lt;i32&gt;</code> and <code>ListArray&lt;i64&gt;</code> (nested arrays)</li>
<li><code>FixedSizeListArray</code> (nested arrays of fixed size)</li>
<li><code>StructArray</code> (when each row has different logical types)</li>
<li><code>DictionaryArray&lt;K&gt;</code> (nested array with encoded values)</li>
</ul>
<h2 id="dynamic-array"><a class="header" href="#dynamic-array">Dynamic Array</a></h2>
<p>There is a more powerful aspect of arrow arrays, and that is that they all
implement the trait <code>Array</code> and can be cast to <code>&amp;dyn Array</code>, i.e. they can be turned into
a trait object. This enables arrays to have types that are dynamic in nature.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::sync::Arc;
</span><span class="boring">use arrow2::array::{Array, PrimitiveArray};
</span><span class="boring">use arrow2::datatypes::DataType;
</span><span class="boring">fn main() {
</span>let data = vec![
    Some(vec![Some(1i32), Some(2), Some(3)]),
    None,
    Some(vec![Some(4), None, Some(6)]),
];

let a = PrimitiveArray::&lt;i32&gt;::from(&amp;[Some(1), None]);
let a: &amp;dyn Array = &amp;a;
<span class="boring">}
</span></code></pre></pre>
<p>Note how we have not specified the inner type explicitly in the signature <code>ListArray&lt;i32&gt;</code>.
Instead, <code>ListArray</code> has an inner <code>Array</code> representing all its values (available via <code>.values()</code>).</p>
<h3 id="downcast-and-as_any"><a class="header" href="#downcast-and-as_any">Downcast and <code>as_any</code></a></h3>
<p>Given a trait object <code>&amp;dyn Array</code>, we know its logical type via <code>Array::data_type()</code> and can use it to downcast the array to its concrete type:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use arrow2::array::{Array, PrimitiveArray};
</span><span class="boring">use arrow2::datatypes::DataType;
</span><span class="boring">fn main() {
</span>let array = [Some(1), None, Some(123)]
    .iter()
    .collect::&lt;PrimitiveArray&lt;i32&gt;&gt;();
let array = &amp;array as &amp;dyn Array;

let array = array.as_any().downcast_ref::&lt;PrimitiveArray&lt;i32&gt;&gt;().unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>There is a many-to-one relationship between <code>DataType</code> and an Array (i.e. a physical representation). The relationship is the following:</p>
<table><thead><tr><th><code>DataType</code></th><th><code>PhysicalType</code></th></tr></thead><tbody>
<tr><td><code>UInt8</code></td><td><code>PrimitiveArray&lt;u8&gt;</code></td></tr>
<tr><td><code>UInt16</code></td><td><code>PrimitiveArray&lt;u16&gt;</code></td></tr>
<tr><td><code>UInt32</code></td><td><code>PrimitiveArray&lt;u32&gt;</code></td></tr>
<tr><td><code>UInt64</code></td><td><code>PrimitiveArray&lt;u64&gt;</code></td></tr>
<tr><td><code>Int8</code></td><td><code>PrimitiveArray&lt;i8&gt;</code></td></tr>
<tr><td><code>Int16</code></td><td><code>PrimitiveArray&lt;i16&gt;</code></td></tr>
<tr><td><code>Int32</code></td><td><code>PrimitiveArray&lt;i32&gt;</code></td></tr>
<tr><td><code>Int64</code></td><td><code>PrimitiveArray&lt;i64&gt;</code></td></tr>
<tr><td><code>Float32</code></td><td><code>PrimitiveArray&lt;f32&gt;</code></td></tr>
<tr><td><code>Float64</code></td><td><code>PrimitiveArray&lt;f64&gt;</code></td></tr>
<tr><td><code>Decimal(_,_)</code></td><td><code>PrimitiveArray&lt;i128&gt;</code></td></tr>
<tr><td><code>Date32</code></td><td><code>PrimitiveArray&lt;i32&gt;</code></td></tr>
<tr><td><code>Date64</code></td><td><code>PrimitiveArray&lt;i64&gt;</code></td></tr>
<tr><td><code>Time32(_)</code></td><td><code>PrimitiveArray&lt;i32&gt;</code></td></tr>
<tr><td><code>Time64(_)</code></td><td><code>PrimitiveArray&lt;i64&gt;</code></td></tr>
<tr><td><code>Timestamp(_,_)</code></td><td><code>PrimitiveArray&lt;i64&gt;</code></td></tr>
<tr><td><code>Interval(YearMonth)</code></td><td><code>PrimitiveArray&lt;i32&gt;</code></td></tr>
<tr><td><code>Interval(DayTime)</code></td><td><code>PrimitiveArray&lt;days_ms&gt;</code></td></tr>
<tr><td><code>Duration(_)</code></td><td><code>PrimitiveArray&lt;i64&gt;</code></td></tr>
<tr><td><code>Binary</code></td><td><code>BinaryArray&lt;i32&gt;</code></td></tr>
<tr><td><code>LargeBinary</code></td><td><code>BinaryArray&lt;i64&gt;</code></td></tr>
<tr><td><code>Utf8</code></td><td><code>Utf8Array&lt;i32&gt;</code></td></tr>
<tr><td><code>LargeUtf8</code></td><td><code>Utf8Array&lt;i64&gt;</code></td></tr>
<tr><td><code>List</code></td><td><code>ListArray&lt;i32&gt;</code></td></tr>
<tr><td><code>LargeList</code></td><td><code>ListArray&lt;i64&gt;</code></td></tr>
<tr><td><code>FixedSizeBinary(_)</code></td><td><code>FixedSizeBinaryArray</code></td></tr>
<tr><td><code>FixedSizeList(_,_)</code></td><td><code>FixedSizeListArray</code></td></tr>
<tr><td><code>Struct(_)</code></td><td><code>StructArray</code></td></tr>
<tr><td><code>Dictionary(UInt8,_)</code></td><td><code>DictionaryArray&lt;u8&gt;</code></td></tr>
<tr><td><code>Dictionary(UInt16,_)</code></td><td><code>DictionaryArray&lt;u16&gt;</code></td></tr>
<tr><td><code>Dictionary(UInt32,_)</code></td><td><code>DictionaryArray&lt;u32&gt;</code></td></tr>
<tr><td><code>Dictionary(UInt64,_)</code></td><td><code>DictionaryArray&lt;u64&gt;</code></td></tr>
<tr><td><code>Dictionary(Int8,_)</code></td><td><code>DictionaryArray&lt;i8&gt;</code></td></tr>
<tr><td><code>Dictionary(Int16,_)</code></td><td><code>DictionaryArray&lt;i16&gt;</code></td></tr>
<tr><td><code>Dictionary(Int32,_)</code></td><td><code>DictionaryArray&lt;i32&gt;</code></td></tr>
<tr><td><code>Dictionary(Int64,_)</code></td><td><code>DictionaryArray&lt;i64&gt;</code></td></tr>
</tbody></table>
<p>In this context, a common pattern to write operators that receive <code>&amp;dyn Array</code> is:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use arrow2::datatypes::DataType;
use arrow2::array::{Array, PrimitiveArray};

fn float_operator(array: &amp;dyn Array) -&gt; Result&lt;Box&lt;dyn Array&gt;, String&gt; {
    match array.data_type() {
        DataType::Float32 =&gt; {
            let array = array.as_any().downcast_ref::&lt;PrimitiveArray&lt;f32&gt;&gt;().unwrap();
            // let array = f32-specific operator
            let array = array.clone();
            Ok(Box::new(array))
        }
        DataType::Float64 =&gt; {
            let array = array.as_any().downcast_ref::&lt;PrimitiveArray&lt;f64&gt;&gt;().unwrap();
            // let array = f64-specific operator
            let array = array.clone();
            Ok(Box::new(array))
        }
        _ =&gt; Err(&quot;This operator is only valid for float point.&quot;.to_string()),
    }
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="from-iterator"><a class="header" href="#from-iterator">From Iterator</a></h2>
<p>In the examples above, we've introduced how to create an array from an iterator.
These APIs are available for all Arrays, and they are suitable to efficiently
create them. In this section we will go a bit more in detail about these operations,
and how to make them even more efficient.</p>
<p>This crate's APIs are generally split into two patterns: whether an operation leverages
contiguous memory regions or whether it does not.</p>
<p>If yes, then use:</p>
<ul>
<li><code>Buffer::from_iter</code></li>
<li><code>Buffer::from_trusted_len_iter</code></li>
<li><code>Buffer::try_from_trusted_len_iter</code></li>
</ul>
<p>If not, then use the builder API, such as <code>MutablePrimitiveArray&lt;T&gt;</code>, <code>MutableUtf8Array&lt;O&gt;</code> or <code>MutableListArray</code>.</p>
<p>We have seen examples where the latter API was used. In the last example of this page
you will be introduced to an example of using the former for SIMD.</p>
<h2 id="into-iterator"><a class="header" href="#into-iterator">Into Iterator</a></h2>
<p>We've already seen how to create an array from an iterator. Most arrays also implement
<code>IntoIterator</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use arrow2::array::{Array, Int32Array};
</span><span class="boring">fn main() {
</span>let array = Int32Array::from(&amp;[Some(1), None, Some(123)]);

for item in array.iter() {
    if let Some(value) = item {
        println!(&quot;{}&quot;, value);
    } else {
        println!(&quot;NULL&quot;);
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>Like <code>FromIterator</code>, this crate contains two sets of APIs to iterate over data. Given
an array <code>array: &amp;PrimitiveArray&lt;T&gt;</code>, the following applies:</p>
<ol>
<li>If you need to iterate over <code>Option&lt;&amp;T&gt;</code>, use <code>array.iter()</code></li>
<li>If you can operate over the values and validity independently, use <code>array.values() -&gt; &amp;Buffer&lt;T&gt;</code> and <code>array.validity() -&gt; &amp;Option&lt;Bitmap&gt;</code></li>
</ol>
<p>Note that case 1 is useful when e.g. you want to perform an operation that depends on both validity and values, while the latter is suitable for SIMD and copies, as they return contiguous memory regions (buffers and bitmaps). We will see below how to leverage these APIs.</p>
<p>This idea holds more generally in this crate's arrays: <code>values()</code> returns something that has a contiguous in-memory representation, while <code>iter()</code> returns items taking validity into account. To get an iterator over contiguous values, use <code>array.values().iter()</code>.</p>
<p>There is one last API that is worth mentioning, and that is <code>Bitmap::chunks</code>. When performing
bitwise operations, it is often more performant to operate on chunks of bits instead of single bits. <code>chunks</code> offers a <code>TrustedLen</code> of <code>u64</code> with the bits + an extra <code>u64</code> remainder. We expose two functions, <code>unary(Bitmap, Fn) -&gt; Bitmap</code> and <code>binary(Bitmap, Bitmap, Fn) -&gt; Bitmap</code> that use this API to efficiently perform bitmap operations.</p>
<h2 id="vectorized-operations"><a class="header" href="#vectorized-operations">Vectorized operations</a></h2>
<p>One of the main advantages of the arrow format and its memory layout is that
it often enables SIMD. For example, an unary operation <code>op</code> on a <code>PrimitiveArray</code> is likely auto-vectorized on the following code:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use arrow2::buffer::Buffer;
</span><span class="boring">use arrow2::{
</span><span class="boring">    array::{Array, PrimitiveArray},
</span><span class="boring">    types::NativeType,
</span><span class="boring">    datatypes::DataType,
</span><span class="boring">};
</span>
pub fn unary&lt;I, F, O&gt;(array: &amp;PrimitiveArray&lt;I&gt;, op: F, data_type: &amp;DataType) -&gt; PrimitiveArray&lt;O&gt;
where
    I: NativeType,
    O: NativeType,
    F: Fn(I) -&gt; O,
{
    let values = array.values().iter().map(|v| op(*v));
    let values = Buffer::from_trusted_len_iter(values);

    PrimitiveArray::&lt;O&gt;::from_data(data_type.clone(), values, array.validity().clone())
}
<span class="boring">}
</span></code></pre></pre>
<p>Some notes:</p>
<ol>
<li>
<p>We used <code>array.values()</code>, as described above: this operation leverages a contiguous memory region.</p>
</li>
<li>
<p>We leveraged normal rust iterators for the operation.</p>
</li>
<li>
<p>We used <code>op</code> on the array's values irrespectively of their validity,
and cloned its validity. This approach is suitable for operations whose branching off is more expensive than operating over all values. If the operation is expensive, then using <code>PrimitiveArray::&lt;O&gt;::from_trusted_len_iter</code> is likely faster.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="compute-api"><a class="header" href="#compute-api">Compute API</a></h1>
<p>When compiled with the feature <code>compute</code>, this crate offers a wide range of functions to perform both vertical (e.g. add two arrays) and horizontal (compute the sum of an array) operations.</p>
<pre><pre class="playground"><code class="language-rust">use arrow2::array::{Array, PrimitiveArray};
use arrow2::compute::arithmetics::*;
use arrow2::compute::arity::{binary, unary};
use arrow2::datatypes::DataType;
use arrow2::error::Result;

fn main() -&gt; Result&lt;()&gt; {
    // say we have two arrays
    let array0 = PrimitiveArray::&lt;i64&gt;::from(&amp;[Some(1), Some(2), Some(3)]);
    let array1 = PrimitiveArray::&lt;i64&gt;::from(&amp;[Some(4), None, Some(6)]);

    // we can add them as follows:
    let added = arithmetic_primitive(&amp;array0, Operator::Add, &amp;array1)?;
    assert_eq!(
        added,
        PrimitiveArray::&lt;i64&gt;::from(&amp;[Some(5), None, Some(9)])
    );

    // subtract:
    let subtracted = arithmetic_primitive(&amp;array0, Operator::Subtract, &amp;array1)?;
    assert_eq!(
        subtracted,
        PrimitiveArray::&lt;i64&gt;::from(&amp;[Some(-3), None, Some(-3)])
    );

    // add a scalar:
    let plus10 = arithmetic_primitive_scalar(&amp;array0, Operator::Add, &amp;10)?;
    assert_eq!(
        plus10,
        PrimitiveArray::&lt;i64&gt;::from(&amp;[Some(11), Some(12), Some(13)])
    );

    // when the array is a trait object, there is a similar API
    let array0 = &amp;array0 as &amp;dyn Array;
    let array1 = &amp;array1 as &amp;dyn Array;

    // check whether the logical types support addition (they could be any `Array`).
    assert!(can_arithmetic(
        array0.data_type(),
        Operator::Add,
        array1.data_type()
    ));

    // add them
    let added = arithmetic(array0, Operator::Add, array1).unwrap();
    assert_eq!(
        PrimitiveArray::&lt;i64&gt;::from(&amp;[Some(5), None, Some(9)]),
        added.as_ref(),
    );

    // a more exotic implementation: arbitrary binary operations
    // this is compiled to SIMD when intrinsics exist.
    let array0 = PrimitiveArray::&lt;i64&gt;::from(&amp;[Some(1), Some(2), Some(3)]);
    let array1 = PrimitiveArray::&lt;i64&gt;::from(&amp;[Some(4), None, Some(6)]);

    let op = |x: i64, y: i64| x.pow(2) + y.pow(2);
    let r = binary(&amp;array0, &amp;array1, DataType::Int64, op)?;
    assert_eq!(
        r,
        PrimitiveArray::&lt;i64&gt;::from(&amp;[Some(1 + 16), None, Some(9 + 36)])
    );

    // arbitrary unary operations
    // this is compiled to SIMD when intrinsics exist.
    let array0 = PrimitiveArray::&lt;f64&gt;::from(&amp;[Some(4.0), None, Some(6.0)]);
    let r = unary(
        &amp;array0,
        |x| x.cos().powi(2) + x.sin().powi(2),
        DataType::Float64,
    );
    assert!((r.values()[0] - 1.0).abs() &lt; 0.0001);
    assert!(r.is_null(1));
    assert!((r.values()[2] - 1.0).abs() &lt; 0.0001);

    // finally, a transformation that changes types:
    let array0 = PrimitiveArray::&lt;f64&gt;::from(&amp;[Some(4.4), None, Some(4.6)]);
    let rounded = unary(&amp;array0, |x| x.round() as i64, DataType::Int64);
    assert_eq!(
        rounded,
        PrimitiveArray::&lt;i64&gt;::from(&amp;[Some(4), None, Some(5)])
    );

    Ok(())
}
</code></pre></pre>
<p>An overview of the implemented functionality.</p>
<ul>
<li>arithmetics, checked, saturating, etc.</li>
<li><code>sum</code>, <code>min</code> and <code>max</code></li>
<li><code>unary</code>, <code>binary</code>, etc.</li>
<li><code>comparison</code></li>
<li><code>cast</code></li>
<li><code>take</code>, <code>filter</code>, <code>concat</code></li>
<li><code>sort</code>, <code>hash</code>, <code>merge-sort</code></li>
<li><code>if-then-else</code></li>
<li><code>nullif</code></li>
<li><code>lenght</code> (of string)</li>
<li><code>hour</code>, <code>year</code> (of temporal logical types)</li>
<li><code>regex</code></li>
<li>(list) <code>contains</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="metadata"><a class="header" href="#metadata">Metadata</a></h1>
<pre><pre class="playground"><code class="language-rust">use std::collections::{BTreeMap, HashMap};

use arrow2::datatypes::{DataType, Field, Schema};

fn main() {
    // two data types (logical types)
    let type1_ = DataType::Date32;
    let type2_ = DataType::Int32;

    // two fields (columns)
    let field1 = Field::new(&quot;c1&quot;, type1_, true);
    let field2 = Field::new(&quot;c2&quot;, type2_, true);

    // which can contain extra metadata:
    let mut metadata = BTreeMap::new();
    metadata.insert(
        &quot;Office Space&quot;.to_string(),
        &quot;Deals with real issues in the workplace.&quot;.to_string(),
    );
    let field1 = field1.with_metadata(metadata);

    // a schema (a table)
    let schema = Schema::new(vec![field1, field2]);

    assert_eq!(schema.fields().len(), 2);

    // which can also contain extra metadata:
    let mut metadata = HashMap::new();
    metadata.insert(
        &quot;Office Space&quot;.to_string(),
        &quot;Deals with real issues in the workplace.&quot;.to_string(),
    );
    let schema = schema.with_metadata(metadata);

    assert_eq!(schema.fields().len(), 2);
}
</code></pre></pre>
<h2 id="datatype-logical-types"><a class="header" href="#datatype-logical-types"><code>DataType</code> (Logical types)</a></h2>
<p>The Arrow specification contains a set of logical types, an enumeration of the different
semantical types defined in Arrow.</p>
<p>In Arrow2, logical types are declared as variants of the <code>enum</code> <code>arrow2::datatypes::DataType</code>.
For example, <code>DataType::Int32</code> represents a signed integer of 32 bits.</p>
<p>Each logical type has an associated in-memory physical representation and is associated to specific
semantics. For example, <code>Date32</code> has the same in-memory representation as <code>Int32</code>, but the value
represents the number of days since UNIX epoch.</p>
<p>Logical types are metadata: they annotate arrays with extra information about in-memory data.</p>
<h2 id="field-column-metadata"><a class="header" href="#field-column-metadata"><code>Field</code> (column metadata)</a></h2>
<p>Besides logical types, the arrow format supports other relevant metadata to the format. All this 
information is stored in <code>arrow2::datatypes::Field</code>.</p>
<p>A <code>Field</code> is arrow's metadata associated to a column in the context of a columnar format. 
It has a name, a logical type <code>DataType</code>, whether the column is nullable, etc.</p>
<h2 id="schema-table-metadata"><a class="header" href="#schema-table-metadata"><code>Schema</code> (table metadata)</a></h2>
<p>The most common use of <code>Field</code> is to declare a <code>arrow2::datatypes::Schema</code>, a sequence of <code>Field</code>s
with optional metadata.</p>
<p><code>Schema</code> is essentially metadata of a &quot;table&quot;: it has a sequence of named columns and their metadata (<code>Field</code>s) with optional metadata.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="foreign-interfaces"><a class="header" href="#foreign-interfaces">Foreign Interfaces</a></h1>
<p>One of the hallmarks of the Arrow format is that its in-memory representation
has a specification, which allows languages to share data
structures via foreign interfaces at zero cost (i.e. via pointers).
This is known as the <a href="https://arrow.apache.org/docs/format/CDataInterface.html">C Data interface</a>.</p>
<p>This crate supports importing from and exporting to most of <code>DataType</code>s.
Types currently not supported:</p>
<ul>
<li><code>FixedSizeBinary</code></li>
<li><code>Union</code></li>
<li><code>Dictionary</code></li>
<li><code>FixedSizeList</code></li>
<li><code>Null</code></li>
</ul>
<h2 id="export"><a class="header" href="#export">Export</a></h2>
<p>The API to export an <code>Array</code> is as follows:</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::Arc;
use arrow2::array::{Array, PrimitiveArray};
use arrow2::datatypes::DataType;
use arrow2::ffi::ArrowArray;

<span class="boring">fn main() {
</span>// Example of an array:
let array = [Some(1), None, Some(123)]
    .iter()
    .collect::&lt;PrimitiveArray&lt;i32&gt;&gt;()
    .to(DataType::Int32);

// export the array.
let ffi_array = ffi::export_to_c(Arc::new(array))?;

// these are mutable pointers to `ArrowArray` and `ArrowSchema` of the C data interface
let (array_ptr, schema_ptr) = ffi_array.references();
<span class="boring">}
</span></code></pre></pre>
<h2 id="import"><a class="header" href="#import">Import</a></h2>
<p>The API to import works similarly:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use arrow2::array::Array;
use arrow2::ffi;

let array = Arc::new(ffi::create_empty());

// non-owned mutable pointers.
let (array_ptr, schema_ptr) = array.references();

// write to the pointers using any C data interface exporter

// consume it to a `Box&lt;dyn Array&gt;`
let array = ffi::try_from(array)?;
<span class="boring">}
</span></code></pre></pre>
<p>This assumes that the exporter writes to <code>array_ptr</code> and <code>schema_ptr</code> 
according to the c data interface. This is an intrinsically <code>unsafe</code> operation.
Failing to do so results in UB.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="io"><a class="header" href="#io">IO</a></h1>
<p>This crate offers optional features that enable interoperability with different formats:</p>
<ul>
<li>Arrow (<code>io_ipc</code>)</li>
<li>CSV (<code>io_csv</code>)</li>
<li>Parquet (<code>io_parquet</code>)</li>
<li>Json (<code>io_json</code>)</li>
</ul>
<p>In this section you can find a guide and examples for each one of them.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="csv-reader"><a class="header" href="#csv-reader">CSV reader</a></h1>
<p>When compiled with feature <code>io_csv</code>, you can use this crate to read CSV files.
This crate makes minimal assumptions on how you want to read a CSV, and offers a large degree of customization to it, along with a useful default.</p>
<h2 id="background"><a class="header" href="#background">Background</a></h2>
<p>There are two CPU-intensive tasks in reading a CSV file:</p>
<ul>
<li>split the CSV file into rows, which includes parsing quotes and delimiters, and is necessary to <code>seek</code> to a given row.</li>
<li>parse a set of CSV rows (bytes) into a <code>RecordBatch</code>.</li>
</ul>
<p>Parsing bytes into values is more expensive than interpreting lines. As such, it is generally advantageous to have multiple readers of a single file that scan different parts of the file (within IO constraints).</p>
<p>This crate relies on <a href="https://crates.io/crates/csv">the crate <code>csv</code></a> to scan and seek CSV files, and your code also needs such a dependency. With that said, <code>arrow2</code> makes no assumptions as to how to efficiently read the CSV: as a single reader per file or multiple readers.</p>
<p>As an example, the following infers the schema and reads a CSV by re-using the same reader:</p>
<pre><pre class="playground"><code class="language-rust">use arrow2::error::Result;
use arrow2::io::csv::read;
use arrow2::record_batch::RecordBatch;

fn read_path(path: &amp;str, projection: Option&lt;&amp;[usize]&gt;) -&gt; Result&lt;RecordBatch&gt; {
    // Create a CSV reader. This is typically created on the thread that reads the file and
    // thus owns the read head.
    let mut reader = read::ReaderBuilder::new().from_path(path)?;

    // Infers the schema using the default inferer. The inferer is just a function that maps a string
    // to a `DataType`.
    let schema = read::infer_schema(&amp;mut reader, None, true, &amp;read::infer)?;

    // allocate space to read from CSV to. The size of this vec denotes how many rows are read.
    let mut rows = vec![read::ByteRecord::default(); 100];

    // skip 0 (excluding the header) and read up to 100 rows.
    // this is IO-intensive and performs minimal CPU work. In particular,
    // no deserialization is performed.
    let rows_read = read::read_rows(&amp;mut reader, 0, &amp;mut rows)?;
    let rows = &amp;rows[..rows_read];

    // parse the batches into a `RecordBatch`. This is CPU-intensive, has no IO,
    // and can be performed on a different thread by passing `rows` through a channel.
    read::deserialize_batch(
        rows,
        schema.fields(),
        projection,
        0,
        read::deserialize_column,
    )
}

fn main() -&gt; Result&lt;()&gt; {
    use std::env;
    let args: Vec&lt;String&gt; = env::args().collect();

    let file_path = &amp;args[1];

    let batch = read_path(file_path, None)?;
    println!(&quot;{:?}&quot;, batch);
    Ok(())
}
</code></pre></pre>
<h2 id="orchestration-and-parallelization"><a class="header" href="#orchestration-and-parallelization">Orchestration and parallelization</a></h2>
<p>Because <code>csv</code>'s API is synchronous, the functions above represent the &quot;minimal
unit of synchronous work&quot;, IO and CPU. Note that <code>rows</code> above are <code>Send</code>,
which implies that it is possible to run <code>parse</code> on a separate thread,
thereby maximizing IO throughput. The example below shows how to do just that:</p>
<pre><pre class="playground"><code class="language-rust">use crossbeam_channel::unbounded;

use std::sync::Arc;
use std::thread;
use std::time::SystemTime;

use arrow2::{error::Result, io::csv::read, record_batch::RecordBatch};

fn parallel_read(path: &amp;str) -&gt; Result&lt;Vec&lt;RecordBatch&gt;&gt; {
    let batch_size = 100;
    let has_header = true;
    let projection = None;

    // prepare a channel to send serialized records from threads
    let (tx, rx) = unbounded();

    let mut reader = read::ReaderBuilder::new().from_path(path)?;
    let schema = read::infer_schema(&amp;mut reader, Some(batch_size * 10), has_header, &amp;read::infer)?;
    let schema = Arc::new(schema);

    let start = SystemTime::now();
    // spawn a thread to produce `Vec&lt;ByteRecords&gt;` (IO bounded)
    let child = thread::spawn(move || {
        let mut line_number = 0;
        let mut size = 1;
        while size &gt; 0 {
            let mut rows = vec![read::ByteRecord::default(); batch_size];
            let rows_read = read::read_rows(&amp;mut reader, 0, &amp;mut rows).unwrap();
            rows.truncate(rows_read);
            line_number += rows.len();
            size = rows.len();
            tx.send((rows, line_number)).unwrap();
        }
    });

    let mut children = Vec::new();
    // use 3 consumers of to decompress, decode and deserialize.
    for _ in 0..3 {
        let rx_consumer = rx.clone();
        let consumer_schema = schema.clone();
        let child = thread::spawn(move || {
            let (rows, line_number) = rx_consumer.recv().unwrap();
            let start = SystemTime::now();
            println!(&quot;consumer start - {}&quot;, line_number);
            let batch = read::deserialize_batch(
                &amp;rows,
                consumer_schema.fields(),
                projection,
                0,
                read::deserialize_column,
            )
            .unwrap();
            println!(
                &quot;consumer end - {:?}: {}&quot;,
                start.elapsed().unwrap(),
                line_number,
            );
            batch
        });
        children.push(child);
    }

    child.join().expect(&quot;child thread panicked&quot;);

    let batches = children
        .into_iter()
        .map(|x| x.join().unwrap())
        .collect::&lt;Vec&lt;_&gt;&gt;();
    println!(&quot;Finished - {:?}&quot;, start.elapsed().unwrap());

    Ok(batches)
}

fn main() -&gt; Result&lt;()&gt; {
    use std::env;
    let args: Vec&lt;String&gt; = env::args().collect();
    let file_path = &amp;args[1];

    let batches = parallel_read(file_path)?;
    for batch in batches {
        println!(&quot;{}&quot;, batch.num_rows())
    }
    Ok(())
}
</code></pre></pre>
<h2 id="customization"><a class="header" href="#customization">Customization</a></h2>
<p>In the code above, <code>parser</code> and <code>infer</code> allow for customization: they declare
how rows of bytes should be inferred (into a logical type), and processed (into a value of said type).
They offer good default options, but you can customize the inference and parsing to your own needs.
You can also of course decide to parse everything into memory as <code>Utf8Array</code> and
delay any data transformation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="write-csv"><a class="header" href="#write-csv">Write CSV</a></h1>
<p>When compiled with feature <code>io_csv</code>, you can use this crate to write CSV files.</p>
<p>This crate relies on <a href="https://crates.io/crates/csv">the crate csv</a> to write well-formed CSV files, which your code should also depend on.</p>
<p>The following example writes a batch as a CSV file with the default configuration:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use arrow2::io::csv::write;
use arrow2::record_batch::RecordBatch;
use arrow2::error::Result;

fn write_batch(path: &amp;str, batches: &amp;[RecordBatch]) -&gt; Result&lt;()&gt; {
    let writer = &amp;mut write::WriterBuilder::new().from_path(path)?;

    write::write_header(writer, batches[0].schema())?;

    let options = write::SerializeOptions::default();
    batches.iter().try_for_each(|batch| {
        write::write_batch(writer, batch, &amp;options)
    })
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="parallelism"><a class="header" href="#parallelism">Parallelism</a></h2>
<p>This crate exposes functionality to decouple serialization from writing.</p>
<p>In the example above, the serialization and writing to a file is done synchronously.
However, these typically deal with different bounds: serialization is often CPU bounded, while writing is often IO bounded. We can trade-off these through a higher memory usage.</p>
<p>Suppose that we know that we are getting CPU-bounded at serialization, and would like to offload that workload to other threads, at the cost of a higher memory usage. We would achieve this as follows (two batches for simplicity):</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::mpsc::{Sender, Receiver};
use std::sync::mpsc;
use std::thread;

use arrow2::io::csv::write;
use arrow2::record_batch::RecordBatch;
use arrow2::error::Result;

fn parallel_write(path: &amp;str, batches: [RecordBatch; 2]) -&gt; Result&lt;()&gt; {
    let options = write::SerializeOptions::default();

    // write a header
    let writer = &amp;mut write::WriterBuilder::new().from_path(path)?;
    write::write_header(writer, batches[0].schema())?;

    // prepare a channel to send serialized records from threads
    let (tx, rx): (Sender&lt;_&gt;, Receiver&lt;_&gt;) = mpsc::channel();
    let mut children = Vec::new();

    for id in 0..2 {
        // The sender endpoint can be copied
        let thread_tx = tx.clone();

        let options = options.clone();
        let batch = batches[id].clone();  // note: this is cheap
        let child = thread::spawn(move || {
            let records = write::serialize(&amp;batch, &amp;options).unwrap();
            thread_tx.send(records).unwrap();
        });

        children.push(child);
    }

    for _ in 0..2 {
        // block: assumes that the order of batches matter.
        let records = rx.recv().unwrap();
        records.iter().try_for_each(|record| {
            writer.write_byte_record(record)
        })?
    }

    for child in children {
        child.join().expect(&quot;child thread panicked&quot;);
    }

    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="read-parquet"><a class="header" href="#read-parquet">Read parquet</a></h1>
<p>When compiled with feature <code>io_parquet</code>, this crate can be used to read parquet files
to arrow.
It makes minimal assumptions on how you to decompose CPU and IO intensive tasks.</p>
<p>First, some notation:</p>
<ul>
<li><code>page</code>: part of a column (e.g. similar of a slice of an <code>Array</code>)</li>
<li><code>column chunk</code>: composed of multiple pages (similar of an <code>Array</code>)</li>
<li><code>row group</code>: a group of columns with the same length (similar of a <code>RecordBatch</code> in Arrow)</li>
</ul>
<p>Here is how to read a single column chunk from a single row group:</p>
<pre><pre class="playground"><code class="language-rust">use std::fs::File;

use arrow2::io::parquet::read;
use arrow2::{array::Array, error::Result};

fn read_column_chunk(path: &amp;str, row_group: usize, column: usize) -&gt; Result&lt;Box&lt;dyn Array&gt;&gt; {
    // Open a file, a common operation in Rust
    let mut file = File::open(path)?;

    // Read the files' metadata. This has a small IO cost because it requires seeking to the end
    // of the file to read its footer.
    let file_metadata = read::read_metadata(&amp;mut file)?;

    // Convert the files' metadata into an arrow schema. This is CPU-only and amounts to
    // parse thrift if the arrow format is available on a key, or infering the arrow schema from
    // the parquet's physical, converted and logical types.
    let arrow_schema = read::get_schema(&amp;file_metadata)?;

    // Construct an iterator over pages. This binds `file` to this iterator, and each iteration
    // is IO intensive as it will read a compressed page into memory. There is almost no CPU work
    // on this operation
    let pages =
        read::get_page_iterator(&amp;file_metadata, row_group, column, &amp;mut file, None, vec![])?;

    // get the columns' metadata
    let metadata = file_metadata.row_groups[row_group].column(column);

    // get the columns' logical type
    let data_type = arrow_schema.fields()[column].data_type().clone();

    // This is the actual work. In this case, pages are read (by calling `iter.next()`) and are
    // immediately decompressed, decoded, deserialized to arrow and deallocated.
    // This uses a combination of IO and CPU. At this point, `array` is the arrow-corresponding
    // array of the parquets' physical type.
    // `Decompressor` re-uses an internal buffer for de-compression, thereby maximizing memory re-use.
    let mut pages = read::Decompressor::new(pages, vec![]);

    read::page_iter_to_array(&amp;mut pages, metadata, data_type)
}

fn main() -&gt; Result&lt;()&gt; {
    use std::env;
    let args: Vec&lt;String&gt; = env::args().collect();

    let file_path = &amp;args[1];
    let column = args[2].parse::&lt;usize&gt;().unwrap();
    let row_group = args[3].parse::&lt;usize&gt;().unwrap();

    let array = read_column_chunk(file_path, row_group, column)?;
    println!(&quot;{}&quot;, array);
    Ok(())
}
</code></pre></pre>
<p>The example above minimizes memory usage at the expense of mixing IO and CPU tasks
on the same thread, which may hurt performance if one of them is a bottleneck.</p>
<p>For single-threaded reading, buffers used to read and decompress pages can be re-used.
This create offers an API that encapsulates the above logic:</p>
<pre><pre class="playground"><code class="language-rust">use std::fs::File;
use std::sync::Arc;

use arrow2::error::Result;
use arrow2::io::parquet::read;

fn main() -&gt; Result&lt;()&gt; {
    use std::env;
    let args: Vec&lt;String&gt; = env::args().collect();

    let file_path = &amp;args[1];

    let reader = File::open(file_path)?;
    let reader = read::RecordReader::try_new(reader, None, None, Arc::new(|_, _| true), None)?;

    for maybe_batch in reader {
        let batch = maybe_batch?;
        println!(&quot;{:?}&quot;, batch);
    }
    Ok(())
}
</code></pre></pre>
<h3 id="parallelism-decoupling-of-cpu-from-io"><a class="header" href="#parallelism-decoupling-of-cpu-from-io">Parallelism decoupling of CPU from IO</a></h3>
<p>One important aspect of the pages created by the iterator above is that they can cross
thread boundaries. Consequently, the thread reading pages from a file (IO-bounded)
does not have to be the same thread performing CPU-bounded work (decompressing,
decoding, etc.).</p>
<p>The example below assumes that CPU starves the consumption of pages,
and that it is advantageous to have a single thread performing all IO-intensive work,
by delegating all CPU-intensive tasks to separate threads.</p>
<pre><pre class="playground"><code class="language-rust">use crossbeam_channel::unbounded;

use std::fs::File;
use std::sync::Arc;
use std::thread;
use std::time::SystemTime;

use arrow2::{array::Array, error::Result, io::parquet::read};

fn parallel_read(path: &amp;str) -&gt; Result&lt;Vec&lt;Box&lt;dyn Array&gt;&gt;&gt; {
    // prepare a channel to send serialized records from threads
    let (tx, rx) = unbounded();

    let mut file = File::open(path)?;
    let file_metadata = read::read_metadata(&amp;mut file)?;
    let arrow_schema = Arc::new(read::get_schema(&amp;file_metadata)?);

    let file_metadata = Arc::new(file_metadata);

    let start = SystemTime::now();
    // spawn a thread to produce `Vec&lt;CompressedPage&gt;` (IO bounded)
    let producer_metadata = file_metadata.clone();
    let child = thread::spawn(move || {
        for column in 0..producer_metadata.schema().num_columns() {
            for row_group in 0..producer_metadata.row_groups.len() {
                let start = SystemTime::now();
                println!(&quot;produce start: {} {}&quot;, column, row_group);
                let pages = read::get_page_iterator(
                    &amp;producer_metadata,
                    row_group,
                    column,
                    &amp;mut file,
                    None,
                    vec![],
                )
                .unwrap()
                .collect::&lt;Vec&lt;_&gt;&gt;();
                println!(
                    &quot;produce end - {:?}: {} {}&quot;,
                    start.elapsed().unwrap(),
                    column,
                    row_group
                );
                tx.send((column, row_group, pages)).unwrap();
            }
        }
    });

    let mut children = Vec::new();
    // use 3 consumers of to decompress, decode and deserialize.
    for _ in 0..3 {
        let rx_consumer = rx.clone();
        let metadata_consumer = file_metadata.clone();
        let arrow_schema_consumer = arrow_schema.clone();
        let child = thread::spawn(move || {
            let (column, row_group, iter) = rx_consumer.recv().unwrap();
            let start = SystemTime::now();
            println!(&quot;consumer start - {} {}&quot;, column, row_group);
            let metadata = metadata_consumer.row_groups[row_group].column(column);
            let data_type = arrow_schema_consumer.fields()[column].data_type().clone();

            let pages = iter
                .into_iter()
                .map(|x| x.and_then(|x| read::decompress(x, &amp;mut vec![])));
            let mut pages = read::streaming_iterator::convert(pages);
            let array = read::page_iter_to_array(&amp;mut pages, metadata, data_type);
            println!(
                &quot;consumer end - {:?}: {} {}&quot;,
                start.elapsed().unwrap(),
                column,
                row_group
            );
            array
        });
        children.push(child);
    }

    child.join().expect(&quot;child thread panicked&quot;);

    let arrays = children
        .into_iter()
        .map(|x| x.join().unwrap())
        .collect::&lt;Result&lt;Vec&lt;_&gt;&gt;&gt;()?;
    println!(&quot;Finished - {:?}&quot;, start.elapsed().unwrap());

    Ok(arrays)
}

fn main() -&gt; Result&lt;()&gt; {
    use std::env;
    let args: Vec&lt;String&gt; = env::args().collect();
    let file_path = &amp;args[1];

    let arrays = parallel_read(file_path)?;
    for array in arrays {
        println!(&quot;{}&quot;, array)
    }
    Ok(())
}
</code></pre></pre>
<p>This can of course be reversed; in configurations where IO is bounded (e.g. when a
network is involved), we can use multiple producers of pages, potentially divided
in file readers, and a single consumer that performs all CPU-intensive work.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="write-to-parquet"><a class="header" href="#write-to-parquet">Write to Parquet</a></h1>
<p>When compiled with feature <code>io_parquet</code>, this crate can be used to write parquet files
from arrow.
It makes minimal assumptions on how you to decompose CPU and IO intensive tasks, as well
as an higher-level API to abstract away some of this work into an easy to use API.</p>
<p>First, some notation:</p>
<ul>
<li><code>page</code>: part of a column (e.g. similar of a slice of an <code>Array</code>)</li>
<li><code>column chunk</code>: composed of multiple pages (similar of an <code>Array</code>)</li>
<li><code>row group</code>: a group of columns with the same length (similar of a <code>RecordBatch</code> in Arrow)</li>
</ul>
<p>Here is an example of how to write a single column chunk into a single row group:</p>
<pre><pre class="playground"><code class="language-rust">use std::fs::File;
use std::iter::once;

use arrow2::io::parquet::write::to_parquet_schema;
use arrow2::{
    array::{Array, Int32Array},
    datatypes::{Field, Schema},
    error::Result,
    io::parquet::write::{
        array_to_page, write_file, Compression, DynIter, Encoding, Version, WriteOptions,
    },
};

fn write_single_array(path: &amp;str, array: &amp;dyn Array, field: Field) -&gt; Result&lt;()&gt; {
    let schema = Schema::new(vec![field]);

    let options = WriteOptions {
        write_statistics: true,
        compression: Compression::Uncompressed,
        version: Version::V2,
    };
    let encoding = Encoding::Plain;

    // map arrow fields to parquet fields
    let parquet_schema = to_parquet_schema(&amp;schema)?;

    // Declare the row group iterator. This must be an iterator of iterators of iterators:
    // * first iterator of row groups
    // * second iterator of column chunks
    // * third iterator of pages
    // an array can be divided in multiple pages via `.slice(offset, length)` (`O(1)`).
    // All column chunks within a row group MUST have the same length.
    let row_groups = once(Result::Ok(DynIter::new(once(Ok(DynIter::new(
        once(array)
            .zip(parquet_schema.columns().to_vec().into_iter())
            .map(|(array, descriptor)| array_to_page(array, descriptor, options, encoding)),
    ))))));

    // Create a new empty file
    let mut file = File::create(path)?;

    // Write the file. Note that, at present, any error results in a corrupted file.
    write_file(
        &amp;mut file,
        row_groups,
        &amp;schema,
        parquet_schema,
        options,
        None,
    )
}

fn main() -&gt; Result&lt;()&gt; {
    let array = Int32Array::from(&amp;[
        Some(0),
        Some(1),
        Some(2),
        Some(3),
        Some(4),
        Some(5),
        Some(6),
    ]);
    let field = Field::new(&quot;c1&quot;, array.data_type().clone(), true);
    write_single_array(&quot;test.parquet&quot;, &amp;array, field)
}
</code></pre></pre>
<p>For single-threaded writing, this crate offers an API that encapsulates the above logic. It 
assumes that a <code>RecordBatch</code> is mapped to a single row group with a single page per column.</p>
<pre><pre class="playground"><code class="language-rust">use std::fs::File;
use std::sync::Arc;

use arrow2::{
    array::{Array, Int32Array},
    datatypes::{Field, Schema},
    error::Result,
    io::parquet::write::{
        write_file, Compression, Encoding, RowGroupIterator, Version, WriteOptions,
    },
    record_batch::RecordBatch,
};

fn write_batch(path: &amp;str, batch: RecordBatch) -&gt; Result&lt;()&gt; {
    let schema = batch.schema().clone();

    let options = WriteOptions {
        write_statistics: true,
        compression: Compression::Uncompressed,
        version: Version::V2,
    };

    let iter = vec![Ok(batch)];

    let row_groups =
        RowGroupIterator::try_new(iter.into_iter(), &amp;schema, options, vec![Encoding::Plain])?;

    // Create a new empty file
    let mut file = File::create(path)?;

    // Write the file. Note that, at present, any error results in a corrupted file.
    let parquet_schema = row_groups.parquet_schema().clone();
    write_file(
        &amp;mut file,
        row_groups,
        &amp;schema,
        parquet_schema,
        options,
        None,
    )
}

fn main() -&gt; Result&lt;()&gt; {
    let array = Int32Array::from(&amp;[
        Some(0),
        Some(1),
        Some(2),
        Some(3),
        Some(4),
        Some(5),
        Some(6),
    ]);
    let field = Field::new(&quot;c1&quot;, array.data_type().clone(), true);
    let schema = Schema::new(vec![field]);
    let batch = RecordBatch::try_new(Arc::new(schema), vec![Arc::new(array)])?;

    write_batch(&quot;test.parquet&quot;, batch)
}
</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="read-arrow"><a class="header" href="#read-arrow">Read Arrow</a></h1>
<p>When compiled with feature <code>io_ipc</code>, this crate can be used to read Arrow files.</p>
<p>An Arrow file is composed by a header, a footer, and blocks of <code>RecordBatch</code>es.
Reading it generally consists of:</p>
<ol>
<li>read metadata, containing the block positions in the file</li>
<li>seek to each block and read it</li>
</ol>
<p>The example below shows how to read them into <code>RecordBatch</code>es:</p>
<pre><pre class="playground"><code class="language-rust">use std::fs::File;

use arrow2::error::Result;
use arrow2::io::ipc::read::{read_file_metadata, FileReader};
use arrow2::io::print;
use arrow2::record_batch::RecordBatch;

fn read_batches(path: &amp;str) -&gt; Result&lt;Vec&lt;RecordBatch&gt;&gt; {
    let mut file = File::open(path)?;

    // read the files' metadata. At this point, we can distribute the read whatever we like.
    let metadata = read_file_metadata(&amp;mut file)?;

    // Simplest way: use the reader, an iterator over batches.
    let reader = FileReader::new(&amp;mut file, metadata, None);

    reader.collect()
}

fn main() -&gt; Result&lt;()&gt; {
    use std::env;
    let args: Vec&lt;String&gt; = env::args().collect();

    let file_path = &amp;args[1];

    let batches = read_batches(file_path)?;
    print::print(&amp;batches);
    Ok(())
}
</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="write-arrow"><a class="header" href="#write-arrow">Write Arrow</a></h1>
<p>When compiled with feature <code>io_ipc</code>, this crate can be used to write Arrow files.</p>
<p>An Arrow file is composed by a header, a footer, and blocks of <code>RecordBatch</code>es.</p>
<p>The example below shows how to write <code>RecordBatch</code>es:</p>
<pre><pre class="playground"><code class="language-rust">use std::fs::File;
use std::sync::Arc;

use arrow2::array::{Int32Array, Utf8Array};
use arrow2::datatypes::{DataType, Field, Schema};
use arrow2::error::Result;
use arrow2::io::ipc::write;
use arrow2::record_batch::RecordBatch;

fn write_batches(path: &amp;str, schema: &amp;Schema, batches: &amp;[RecordBatch]) -&gt; Result&lt;()&gt; {
    let mut file = File::create(path)?;

    let mut writer = write::FileWriter::try_new(&amp;mut file, schema)?;

    for batch in batches {
        writer.write(batch)?
    }
    writer.finish()
}

fn main() -&gt; Result&lt;()&gt; {
    use std::env;
    let args: Vec&lt;String&gt; = env::args().collect();

    let file_path = &amp;args[1];

    // create a batch
    let schema = Schema::new(vec![
        Field::new(&quot;a&quot;, DataType::Int32, false),
        Field::new(&quot;b&quot;, DataType::Utf8, false),
    ]);

    let a = Int32Array::from_slice(&amp;[1, 2, 3, 4, 5]);
    let b = Utf8Array::&lt;i32&gt;::from_slice(&amp;[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;]);

    let batch = RecordBatch::try_new(Arc::new(schema.clone()), vec![Arc::new(a), Arc::new(b)])?;

    // write it
    write_batches(file_path, &amp;schema, &amp;[batch])?;
    Ok(())
}
</code></pre></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
                        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
                
    </body>
</html>
